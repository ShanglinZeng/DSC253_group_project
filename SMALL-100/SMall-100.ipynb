{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def read_binary_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        lines = file.read().decode('utf-8').split('\\n')\n",
    "    return lines\n",
    "\n",
    "\n",
    "gujarati_text = read_binary_file('../test_datasets/dev.guj_Gujr')\n",
    "nepali_text = read_binary_file('../test_datasets/dev.npi_Deva')\n",
    "burmese_text = read_binary_file('../test_datasets/dev.mya_Mymr')\n",
    "khmer_text = read_binary_file('../test_datasets/dev.khm_Khmr')\n",
    "galician_text = read_binary_file('../test_datasets/dev.glg_Latn')\n",
    "english_labels = read_binary_file('../test_datasets/dev.eng_Latn')\n",
    "english_labels = [[i] for i in english_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct language codes for M2M100\n",
    "language_codes = {\n",
    "    'gujarati': 'gu',\n",
    "    'nepali': 'ne',\n",
    "    'burmese': 'my',\n",
    "    'khmer': 'km',\n",
    "    'galician': 'gl',\n",
    "    'english': 'en'\n",
    "}\n",
    "\n",
    "# Test sentences in different languages\n",
    "input_texts = {\n",
    "    'gujarati': gujarati_text,  \n",
    "    'nepali': nepali_text,  \n",
    "    'burmese': burmese_text,  \n",
    "    'khmer': khmer_text,  \n",
    "    'galician': galician_text  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing translation from gujarati to English...\n",
      "BLEU score for gujarati: 0.0\n",
      "Processing translation from nepali to English...\n",
      "BLEU score for nepali: 0.0\n",
      "Processing translation from burmese to English...\n",
      "BLEU score for burmese: 0.0\n",
      "Processing translation from khmer to English...\n",
      "BLEU score for khmer: 0.0\n",
      "Processing translation from galician to English...\n",
      "BLEU score for galician: 0.0\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "# Load the input files\n",
    "def load_input_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Correct language codes for small-100\n",
    "language_codes = {\n",
    "    'gujarati': 'gu',\n",
    "    'nepali': 'ne',\n",
    "    'burmese': 'my',\n",
    "    'khmer': 'km',\n",
    "    'galician': 'gl',\n",
    "    'english': 'en'\n",
    "}\n",
    "\n",
    "# Load the SMaLL-100 model and tokenizer\n",
    "model_name = 'alirezamsh/small100'\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Function to translate text\n",
    "def test_translation(source_text, source_lang, target_lang='en', max_length=128):\n",
    "    input_text = f\"{source_text} </s> {target_lang}\"\n",
    "    encoded_text = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    generated_tokens = model.generate(**encoded_text, max_length=max_length)\n",
    "    translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "# Process translations\n",
    "for lang, text in input_texts.items():\n",
    "    print(f\"Processing translation from {lang} to English...\")\n",
    "    translated_text = test_translation(text, language_codes[lang])\n",
    "    blue_score = sacrebleu.corpus_bleu(translated_text, english_labels)\n",
    "    print(f\"BLEU score for {lang}: {blue_score.score}\")\n",
    "\n",
    "    # Save the translated text to a file\n",
    "    with open(f\"{lang}.txt\", \"w\", encoding='utf-8') as file:\n",
    "        file.write(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "# Load the SMaLL-100 model and tokenizer\n",
    "model_name = 'alirezamsh/small100'\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def translate(src_lang, tokenizer, model, text):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    generated_tokens = model.generate(**encoded_text, \n",
    "                                      forced_bos_token_id=tokenizer.lang_code_to_id['en'])\n",
    "    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "def batch_translate(src_lang, tokenizer, model, texts, batch_size=16):\n",
    "    results = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_results = translate(src_lang, tokenizer, model, batch_texts)\n",
    "        results.extend(batch_results)\n",
    "    return results\n",
    "\n",
    "# Perform translations\n",
    "gujarati_translations = batch_translate(\"gu\", tokenizer, model, gujarati_text)\n",
    "nepali_translations = batch_translate(\"ne\", tokenizer, model, nepali_text)\n",
    "burmese_translations = batch_translate(\"my\", tokenizer, model, burmese_text)\n",
    "khmer_translations = batch_translate(\"km\", tokenizer, model, khmer_text)\n",
    "galician_translations = batch_translate(\"gl\", tokenizer, model, galician_text)\n",
    "\n",
    "# Save translations to files\n",
    "def save_translations(file_name, translations):\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        for line in translations:\n",
    "            file.write(f\"{line}\\n\")\n",
    "\n",
    "save_translations(\"gujarati_translations.txt\", gujarati_translations)\n",
    "save_translations(\"nepali_translations.txt\", nepali_translations)\n",
    "save_translations(\"burmese_translations.txt\", burmese_translations)\n",
    "save_translations(\"khmer_translations.txt\", khmer_translations)\n",
    "save_translations(\"galician_translations.txt\", galician_translations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score on Gujarati: 0.43384866842485925\n",
      "BLEU score on Nepali: 0.9896324688555468\n",
      "BLEU score on Burmese: 8.9730240870212\n",
      "BLEU score on Khmer: 46.713797772819994\n",
      "BLEU score on Galician: 1.1448714311538606\n"
     ]
    }
   ],
   "source": [
    "gujarati_bleu = sacrebleu.corpus_bleu(gujarati_translations, english_labels)\n",
    "print(f\"BLEU score on Gujarati: {gujarati_bleu.score}\")\n",
    "\n",
    "nepali_bleu = sacrebleu.corpus_bleu(nepali_translations, english_labels)\n",
    "print(f\"BLEU score on Nepali: {nepali_bleu.score}\")\n",
    "\n",
    "burmese_bleu = sacrebleu.corpus_bleu(burmese_translations, english_labels)\n",
    "print(f\"BLEU score on Burmese: {burmese_bleu.score}\")\n",
    "\n",
    "khmer_bleu = sacrebleu.corpus_bleu(khmer_translations, english_labels)\n",
    "print(f\"BLEU score on Khmer: {khmer_bleu.score}\")\n",
    "\n",
    "galician_bleu = sacrebleu.corpus_bleu(galician_translations, english_labels)\n",
    "print(f\"BLEU score on Galician: {galician_bleu.score}\")\n",
    "\n",
    "# overall_translations = [[gujarati_translations[i], nepali_translations[i], \n",
    "#                          burmese_translations[i], khmer_translations[i], \n",
    "#                          galician_translations[i]] for i in range(len(english_labels))]\n",
    "\n",
    "# overall_bleu = sacrebleu.corpus_bleu(english_labels, overall_translations)\n",
    "# print(f\"BLEU score on Overall: {overall_bleu.score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

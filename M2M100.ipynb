{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687b9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to load input text files and split by lines\n",
    "def load_input_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read().split('\\n')\n",
    "\n",
    "# Function to read references for BLEU calculation\n",
    "def load_references(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return [[line.decode('utf-8').strip()] for line in file.read().splitlines()]\n",
    "\n",
    "# Function to chunk text\n",
    "def chunk_text(text, max_length=128):\n",
    "    sentences = text\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())\n",
    "        if current_length + sentence_length > max_length:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "        current_chunk.append(sentence)\n",
    "        current_length += sentence_length\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# Function to translate text using the M2M100 model\n",
    "def test_translation(source_text, source_lang, target_lang='en', max_length=128):\n",
    "    tokenizer.src_lang = source_lang\n",
    "    encoded_text = tokenizer(source_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to('cuda')\n",
    "    generated_tokens = model.generate(**encoded_text, forced_bos_token_id=tokenizer.get_lang_id(target_lang),max_length=max_length)\n",
    "    translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2247de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Load input texts\n",
    "input_texts = {\n",
    "    'gujarati': load_input_file('dev.guj_Gujr'),\n",
    "    'galician': load_input_file('dev.glg_Latn'),\n",
    "    'khmer': load_input_file('dev.khm_Khmr'),\n",
    "    'burmese': load_input_file('dev.mya_Mymr'),\n",
    "    'nepali': load_input_file('dev.npi_Deva')\n",
    "}\n",
    "\n",
    "# Load English references\n",
    "english_labels = load_references('dev.eng_Latn')\n",
    "\n",
    "# Language codes for M2M100\n",
    "language_codes = {\n",
    "    'gujarati': 'gu',\n",
    "    'nepali': 'ne',\n",
    "    'burmese': 'my',\n",
    "    'khmer': 'km',\n",
    "    'galician': 'gl',\n",
    "    'english': 'en'\n",
    "}\n",
    "\n",
    "# Load the M2M100 model and tokenizer\n",
    "model_name = 'facebook/m2m100_418M'\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c702c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing translation from gujarati to English...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating gujarati: 100%|██████████| 172/172 [04:05<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for gujarati: 22.66277494897848\n",
      "Processing translation from galician to English...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating galician: 100%|██████████| 195/195 [05:32<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for galician: 46.63945526554835\n",
      "Processing translation from khmer to English...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating khmer: 100%|██████████| 46/46 [00:49<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for khmer: 34.405943453197025\n",
      "Processing translation from burmese to English...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating burmese: 100%|██████████| 82/82 [01:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for burmese: 15.568939784469132\n",
      "Processing translation from nepali to English...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating nepali: 100%|██████████| 151/151 [03:49<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for nepali: 42.31838992507398\n"
     ]
    }
   ],
   "source": [
    "# Process translations and compute BLEU scores\n",
    "for lang, text in input_texts.items():\n",
    "    print(f\"Processing translation from {lang} to English...\")\n",
    "    chunks = chunk_text(text)\n",
    "    translated_chunks = [test_translation(chunk, language_codes[lang]) for chunk in tqdm(chunks, desc=f\"Translating {lang}\")]\n",
    "    bleu_score = sacrebleu.corpus_bleu(translated_chunks, english_labels)\n",
    "    print(f\"BLEU score for {lang}: {bleu_score.score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
